{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Md Abdul Kadir\n",
    "\n",
    "Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importan Methodes\n",
    "# Replace the nan vale with mean, median, or most frequent value\n",
    "def replaceNaN(dataframe, replaceby = \"mean\"):\n",
    "    if (replaceby == \"mean\"):\n",
    "        return dataframe.fillna(dataframe.mean())\n",
    "    \n",
    "    elif (replaceby == \"median\"):\n",
    "        return dataframe.fillna(dataframe.median())\n",
    "    \n",
    "    elif (replaceby == \"mostfrq\"):\n",
    "        return dataframe.fillna(dataframe.mode().iloc[0])\n",
    "    \n",
    "    else:return dataframe.dropna()\n",
    "    \n",
    "# Replce any nonnumaric char from a column.    \n",
    "def replce_char(dataframe,collumn, char=r'^<'):\n",
    "    dataframe[collumn] =  dataframe[collumn].replace(regex=char, value='')\n",
    "    dataframe[collumn] = pd.to_numeric(dataframe[collumn],errors='coerce')\n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "    \n",
    "# Scale the data using standard scaler or max min scaler. Menstion the names to scale. \n",
    "def scale(dataframe, coulumns, scaler=\"ss\"):\n",
    "    if (scaler == \"mm\"):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        dataframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "        return dataframe\n",
    "    elif (scaler == \"ss\"):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        datqframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "        return dataframe\n",
    "    \n",
    "    else:return dataframe\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dtasets\n",
    "\n",
    "# Load Food Supply Data\n",
    "\n",
    "Food_Supply_DF = pd.read_csv(\"../Data/updated_07_06_2020/Food_Supply_Quantity_kg_Data.csv\")\n",
    "Food_Supply_DF = replaceNaN(Food_Supply_DF, replaceby=\"mostfrq\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcoholic Beverages', 'Animal fats', 'Animal Products',\n",
      "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
      "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
      "       'Milk - Excluding Butter', 'Miscellaneous', 'Offals', 'Oilcrops',\n",
      "       'Pulses', 'Spices', 'Starchy Roots', 'Stimulants', 'Sugar & Sweeteners',\n",
      "       'Sugar Crops', 'Treenuts', 'Vegetable Oils', 'Vegetables',\n",
      "       'Vegetal Products', 'Obesity', 'Undernourished', 'Confirmed', 'Deaths',\n",
      "       'Recovered', 'Active'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "##Standard Scaler \n",
    "NOT_IPMORTANT_COLUMNS = [\"Country\", 'Unit (all except Population)', 'Population']\n",
    "\n",
    "clm = Food_Supply_DF.columns.drop(NOT_IPMORTANT_COLUMNS)\n",
    "print(clm)\n",
    "\n",
    "Food_Supply_DF = replce_char(Food_Supply_DF,\"Undernourished\", char=r'^<')\n",
    "scaled_df = scale(Food_Supply_DF, clm, scaler=\"mm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise data\n",
    "scaled_df = scaled_df.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "# scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple regression model for 1 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosse training input and output\n",
    "#XY = scaled_df[['Undernourished','Obesity' ]]\n",
    "#XY.plot.scatter(x = 'Undernourished', y ='Obesity')\n",
    "\n",
    "FEATURE_CLS = ['Obesity', 'Undernourished', 'Deaths','Recovered','Active','Confirmed']\n",
    "FEATURE = ['Obesity', 'Undernourished', 'Deaths','Recovered' ]\n",
    "\n",
    "ALL_OUTPUT = ['Alcoholic Beverages', 'Animal Products', 'Animal fats',\n",
    "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
    "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
    "       'Milk - Excluding Butter', 'Offals', 'Oilcrops', 'Pulses', 'Spices',\n",
    "       'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners',\n",
    "       'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables',\n",
    "       'Miscellaneous']\n",
    "GOOD_OUTPUT =['Animal Products', 'Animal fats','Vegetal Products','Vegetable Oils' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide trian and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(scaled_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold \n",
    "X = pd.DataFrame(scaled_df[FEATURE_CLS])\n",
    "y = pd.DataFrame(scaled_df[GOOD_OUTPUT])\n",
    "model = LinearRegression()\n",
    "scores = []\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "for i, (train, test) in enumerate(kfold.split(X, y)):\n",
    "    model.fit(X.iloc[train,:], y.iloc[train,:])\n",
    "    score = model.score(X.iloc[test,:], y.iloc[test,:])\n",
    "    scores.append(score)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def Regression(features, response, data, method = LinearRegression()):\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    return model.fit(X, Y)\n",
    "    \n",
    "    \n",
    "    \n",
    "def TestScore(features, response, data, model):\n",
    "    print('Output: ', response)\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    return model.score(X,Y)\n",
    "    \n",
    "def PlotRegression(features, response, data, model):\n",
    "    import matplotlib.pyplot as plt\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(X, Y, s=10)\n",
    "    plt.plot(X, y_pred, color='r')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = Regression(FEATURE_CLS, GOOD_OUTPUT, train_set, method = linear_model.Lasso(alpha=0.1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  ['Animal Products', 'Animal fats', 'Vegetal Products', 'Vegetable Oils']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.6181737475778593"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestScore(FEATURE_CLS, GOOD_OUTPUT,test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PlotRegression(FEATURE_CLS, ALL_OUTPUT  ,tra in_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  Alcoholic Beverages\n",
      "R^2 :  0.012966420549500146\n",
      "Output:  Animal Products\n",
      "R^2 :  0.3266763032232859\n",
      "Output:  Animal fats\n",
      "R^2 :  0.10012787125844702\n",
      "Output:  Aquatic Products, Other\n",
      "R^2 :  -46.732919591801796\n",
      "Output:  Cereals - Excluding Beer\n",
      "R^2 :  0.3306840033819963\n",
      "Output:  Eggs\n",
      "R^2 :  0.2878016465935942\n",
      "Output:  Fish, Seafood\n",
      "R^2 :  -0.1800763222310393\n",
      "Output:  Fruits - Excluding Wine\n",
      "R^2 :  -0.0011452530491427027\n",
      "Output:  Meat\n",
      "R^2 :  0.1493667755650725\n",
      "Output:  Milk - Excluding Butter\n",
      "R^2 :  0.17457727080602814\n",
      "Output:  Offals\n",
      "R^2 :  0.019803438466795664\n",
      "Output:  Oilcrops\n",
      "R^2 :  -0.7777524802263442\n",
      "Output:  Pulses\n",
      "R^2 :  0.2348711130733202\n",
      "Output:  Spices\n",
      "R^2 :  0.04288068023189051\n",
      "Output:  Starchy Roots\n",
      "R^2 :  0.1524583645950105\n",
      "Output:  Stimulants\n",
      "R^2 :  -0.06617865551850333\n",
      "Output:  Sugar Crops\n",
      "R^2 :  -0.006897764958550434\n",
      "Output:  Sugar & Sweeteners\n",
      "R^2 :  0.09612198836944597\n",
      "Output:  Treenuts\n",
      "R^2 :  0.016051722632956178\n",
      "Output:  Vegetal Products\n",
      "R^2 :  0.32672663441316774\n",
      "Output:  Vegetable Oils\n",
      "R^2 :  -0.036034529252650715\n",
      "Output:  Vegetables\n",
      "R^2 :  0.11997198761153671\n",
      "Output:  Miscellaneous\n",
      "R^2 :  -0.4294701641663228\n"
     ]
    }
   ],
   "source": [
    "for cls in ALL_OUTPUT:\n",
    "    model = Regression(FEATURE, cls, train_set, method = linear_model.Lasso(alpha=0.5) )\n",
    "    print('R^2 : ', TestScore(FEATURE, cls,test_set, model))\n",
    "    #PlotRegression(FEATURE, cls ,test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score of  Alcoholic Beverages  :  0.012966420549500146\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Animal Products  :  0.3266763032232859\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Animal fats  :  0.10012787125844724\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Aquatic Products, Other  :  -46.732919591801824\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Cereals - Excluding Beer  :  0.3306840033819962\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Eggs  :  0.2878016465935943\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Fish, Seafood  :  -0.18007632223103953\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Fruits - Excluding Wine  :  -0.0011452530491429247\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Meat  :  0.14936677556507227\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Milk - Excluding Butter  :  0.17457727080602814\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Offals  :  0.019803438466795886\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Oilcrops  :  -0.7777524802263442\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Pulses  :  0.23487111307332065\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Spices  :  0.04288068023189029\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Starchy Roots  :  0.1524583645950096\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Stimulants  :  -0.06617865551850333\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Sugar Crops  :  -0.006897764958550212\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Sugar & Sweeteners  :  0.09612198836944619\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Treenuts  :  0.016051722632956178\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Vegetal Products  :  0.3267266344131676\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Vegetable Oils  :  -0.036034529252650715\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Vegetables  :  0.11997198761153682\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n",
      "R^2 Score of  Miscellaneous  :  -0.4294701641663228\n",
      "[0.23920421662986885, -3.1786696492969977, 0.2175182510186099]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import linear_model\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE])\n",
    "    #print(X_train_transformed)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    \n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for i, (train, test) in enumerate(kfold.split(X, y)):\n",
    "        model.fit(X.iloc[train,:], y.iloc[train,:])\n",
    "        score = model.score(X.iloc[test,:], y.iloc[test,:])\n",
    "        scores.append(score)\n",
    "    print(scores)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score of  Alcoholic Beverages  :  0.03965386084765743\n",
      "R^2 Score of  Animal Products  :  0.2818409678086853\n",
      "R^2 Score of  Animal fats  :  0.2488966501554527\n",
      "R^2 Score of  Aquatic Products, Other  :  -1.6823712118679053\n",
      "R^2 Score of  Cereals - Excluding Beer  :  0.17468054968955704\n",
      "R^2 Score of  Eggs  :  0.19160947741222967\n",
      "R^2 Score of  Fish, Seafood  :  -0.30056953540426146\n",
      "R^2 Score of  Fruits - Excluding Wine  :  -0.37285329753555474\n",
      "R^2 Score of  Meat  :  -0.1127824832750921\n",
      "R^2 Score of  Milk - Excluding Butter  :  0.17327533884201818\n",
      "R^2 Score of  Offals  :  -0.09694573834612319\n",
      "R^2 Score of  Oilcrops  :  -6.048387267544269\n",
      "R^2 Score of  Pulses  :  0.23384268393426155\n",
      "R^2 Score of  Spices  :  -0.08779893905487501\n",
      "R^2 Score of  Starchy Roots  :  -1.012288900161058\n",
      "R^2 Score of  Stimulants  :  -0.035189707024323225\n",
      "R^2 Score of  Sugar Crops  :  -0.30892385964715463\n",
      "R^2 Score of  Sugar & Sweeteners  :  -0.05813924159332151\n",
      "R^2 Score of  Treenuts  :  -0.38462477638180315\n",
      "R^2 Score of  Vegetal Products  :  0.2816512736689589\n",
      "R^2 Score of  Vegetable Oils  :  -0.016782613202440233\n",
      "R^2 Score of  Vegetables  :  -0.20261191509616827\n",
      "R^2 Score of  Miscellaneous  :  -1.6417272882366163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(max_depth=2)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE_CLS])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE_CLS])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score of  Alcoholic Beverages  :  -0.056018164418486505\n",
      "R^2 Score of  Animal Products  :  0.2228310191721451\n",
      "R^2 Score of  Animal fats  :  0.15179297651639911\n",
      "R^2 Score of  Aquatic Products, Other  :  -1019.5110111341505\n",
      "R^2 Score of  Cereals - Excluding Beer  :  0.263271199417341\n",
      "R^2 Score of  Eggs  :  0.21431862813213998\n",
      "R^2 Score of  Fish, Seafood  :  -0.10423127050655112\n",
      "R^2 Score of  Fruits - Excluding Wine  :  -0.18934970098517745\n",
      "R^2 Score of  Meat  :  -0.0718318280926673\n",
      "R^2 Score of  Milk - Excluding Butter  :  0.1770147902362431\n",
      "R^2 Score of  Offals  :  -0.1489398333348575\n",
      "R^2 Score of  Oilcrops  :  -0.4792396787348754\n",
      "R^2 Score of  Pulses  :  0.11666434300419559\n",
      "R^2 Score of  Spices  :  0.07353487553901461\n",
      "R^2 Score of  Starchy Roots  :  0.19160087531171255\n",
      "R^2 Score of  Stimulants  :  -0.05900146126968453\n",
      "R^2 Score of  Sugar Crops  :  -0.18342301369347802\n",
      "R^2 Score of  Sugar & Sweeteners  :  0.10790788923753825\n",
      "R^2 Score of  Treenuts  :  -0.006830195896169844\n",
      "R^2 Score of  Vegetal Products  :  0.2229915930114632\n",
      "R^2 Score of  Vegetable Oils  :  -0.12823094223613984\n",
      "R^2 Score of  Vegetables  :  0.049382849784043836\n",
      "R^2 Score of  Miscellaneous  :  0.02374273135538174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model =  SVR(C=1.0, epsilon=0.1)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE_CLS])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE_CLS])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Dataset and model class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset class\n",
    "class NutritionData:\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        dataframe = pd.read_csv(self.data_path)\n",
    "        dataframe = self.__replaceNaN(dataframe, replaceby=\"mostfrq\")\n",
    "        \n",
    "        ##Standard Scaler \n",
    "        NOT_IPMORTANT_COLUMNS = [\"Country\", 'Unit (all except Population)', 'Population']\n",
    "\n",
    "        clm = dataframe.columns.drop(NOT_IPMORTANT_COLUMNS)\n",
    "\n",
    "        dataframe = self.__replace_char(dataframe, \"Undernourished\", char=r'^<')\n",
    "        scaled_df = self.__scale(dataframe, clm, scaler=\"mm\")\n",
    "        scaled_df = scaled_df.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "\n",
    "        self.dataset = scaled_df\n",
    "        \n",
    "    \n",
    "        # Importan Methodes\n",
    "    # Replace the nan vale with mean, median, or most frequent value\n",
    "    def __replaceNaN(self, dataframe, replaceby = \"mean\"):\n",
    "        if (replaceby == \"mean\"):\n",
    "            return dataframe.fillna(dataframe.mean())\n",
    "\n",
    "        elif (replaceby == \"median\"):\n",
    "            return dataframe.fillna(dataframe.median())\n",
    "\n",
    "        elif (replaceby == \"mostfrq\"):\n",
    "            return dataframe.fillna(dataframe.mode().iloc[0])\n",
    "\n",
    "        else:return dataframe.dropna()\n",
    "        \n",
    "        \n",
    "\n",
    "    # Replce any nonnumaric char from a column.    \n",
    "    def __replace_char(self, dataframe, collumn, char=r'^<'):\n",
    "        \n",
    "        dataframe[collumn] =  dataframe[collumn].replace(regex=char, value='')\n",
    "        dataframe[collumn] = pd.to_numeric(dataframe[collumn],errors='coerce')\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "\n",
    "    # Scale the data using standard scaler or max min scaler. Menstion the names to scale. \n",
    "    def __scale(self, dataframe, coulumns, scaler=\"ss\"):\n",
    "        \n",
    "        if (scaler == \"mm\"):\n",
    "            from sklearn.preprocessing import MinMaxScaler\n",
    "            scaler = MinMaxScaler()\n",
    "            dataframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "            return dataframe\n",
    "        elif (scaler == \"ss\"):\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            datqframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "            return dataframe\n",
    "\n",
    "        else:return dataframe\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalizing class to test and train all the models\n",
    "class NutritionModel:\n",
    "    \n",
    "    def __init__(self, dataset=None):\n",
    "        self.dataset = dataset\n",
    "        self.model = None\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "        \n",
    "        \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        # splits the dataset in train and test set\n",
    "        self.train_set, self.test_set  = train_test_split(self.dataset, test_size=test_size, random_state=42)\n",
    "      \n",
    "    \n",
    "    def set_model(self, model):\n",
    "        # setting up the model\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "    def save_model(self, pkl_filename='model.pkl'):\n",
    "        with open(pkl_filename, 'wb') as file:\n",
    "            pickle.dump(self.model, file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def load_model(self, pkl_filename='model.pkl'):\n",
    "        with open(pkl_filename, 'rb') as file:\n",
    "            self.model = pickle.load(file)\n",
    "    \n",
    "        \n",
    "    \n",
    "    def train_model(self, x_column, y_column):\n",
    "        #traing the model\n",
    "        # input arg: x column name, y column names\n",
    "        self.model.fit(self.train_set[x_column], self.train_set[y_column])\n",
    "    \n",
    "    \n",
    "    def test_model(self, x_column, y_column): \n",
    "        score = self.model.score(self.test_set[x_column], self.test_set[y_column])\n",
    "        return score\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_CLS = ['Obesity', 'Undernourished', 'Deaths','Recovered','Active','Confirmed']\n",
    "FEATURE = ['Obesity', 'Undernourished', 'Deaths','Recovered' ]\n",
    "\n",
    "ALL_OUTPUT = ['Alcoholic Beverages', 'Animal Products', 'Animal fats',\n",
    "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
    "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
    "       'Milk - Excluding Butter', 'Offals', 'Oilcrops', 'Pulses', 'Spices',\n",
    "       'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners',\n",
    "       'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables',\n",
    "       'Miscellaneous']\n",
    "GOOD_OUTPUT=['Animal Products', 'Animal fats','Vegetal Products','Vegetable Oils' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())\n",
    "#Parameters currently in use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1, refit=True)\n",
    "# Fit the random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mak/Uni-courses/SS2020/DS/Nutrition-and-immune-systems/log/random_forest/log.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6379a689dd4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(asctime)s - %(name)s - %(levelname)s - %(message)s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfile_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mfile_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfile_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, encoding, delay)\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mStreamHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \"\"\"\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mak/Uni-courses/SS2020/DS/Nutrition-and-immune-systems/log/random_forest/log.txt'"
     ]
    }
   ],
   "source": [
    "log_path = '../log/random_forest/'\n",
    "data_root = '../Data/updated_04_07_2020/Food_Supply_Quantity_kg_Data.csv'\n",
    "\n",
    "# change here\n",
    "data_file = \"Food_Supply_Quantity_kg_Data.csv\"\n",
    "log_file = log_path + 'log.txt'\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Print arguments\n",
    "logger.info('Log file is %s.' % log_file)\n",
    "# logger.info('Data path is %s.' % data_path)\n",
    "# logger.info('Export path is %s.' % xp_path)\n",
    "\n",
    "data_path = data_root + data_file\n",
    "\n",
    "\n",
    "if not os.path.exists(data_file.split('.')[0]):\n",
    "    model_dirs = log_path + data_file.split('.')[0]\n",
    "    os.makedirs(model_dirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../log/Results_Food_Supply_Quantity_kg_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d57e1c8e9fdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfieldnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x_column'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_column'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../log/Results_Food_Supply_Quantity_kg_Data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../log/Results_Food_Supply_Quantity_kg_Data.csv'"
     ]
    }
   ],
   "source": [
    "# model.save_model()\n",
    "# model.load_model()\n",
    "import csv\n",
    "fieldnames = ['model_name', 'x_column', 'y_column', 'score']\n",
    "with open('../log/Results_Food_Supply_Quantity_kg_Data.csv', 'w', newline='') as csvfile:\n",
    "    \n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../log/Results_Food_Supply_Quantity_kg_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-dc1ab81f3c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../log/Results_Food_Supply_Quantity_kg_Data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mALL_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFEATURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../log/Results_Food_Supply_Quantity_kg_Data.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "data_path = \"../Data/updated_07_06_2020/Food_Supply_Quantity_kg_Data.csv\"\n",
    "dataobj = NutritionData(data_path=data_path) # creating dataset\n",
    "\n",
    "# creating model classes\n",
    "model = NutritionModel(dataset=dataobj.dataset)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model.set_model(model=rf_random)\n",
    "model.split_data()\n",
    "\n",
    "with open('../log/Results_Food_Supply_Quantity_kg_Data.csv', 'a', newline='') as csvfile:\n",
    "    for y_val in ALL_OUTPUT:\n",
    "        x_val = FEATURE\n",
    "        model.train_model(x_column=x_val, y_column=y_val)\n",
    "        score = model.test_model(x_column=x_val, y_column=y_val)\n",
    "        model.save_model(pkl_filename=os.path.join(model_dirs, y_val+'.pkl'))\n",
    "        print(score)\n",
    "        obj = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        obj.writerow({'model_name':'Random Forest', 'x_column': x_val, 'y_column': y_val, 'score': score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2385564018604872\n"
     ]
    }
   ],
   "source": [
    "# Tareque \n",
    "\n",
    "# Create class to that take a csv file as an input\n",
    "# Return output prediction \n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "dataobj = NutritionData(data_path=data_path) # creating dataset\n",
    "# creating model classes\n",
    "model = NutritionModel(dataset=dataobj.dataset)\n",
    "\n",
    "model.set_model(model=rf_random)\n",
    "model.split_data()\n",
    "\n",
    "x_val = FEATURE\n",
    "model.train_model(x_column=x_val, y_column=GOOD_OUTPUT)\n",
    "score = model.test_model(x_column=x_val, y_column='')\n",
    "#model.save_model(pkl_filename=os.path.join(, y_val+'.pkl'))\n",
    "print(score)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24156884522415123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "method_names = {}\n",
    "# Adding linear regression\n",
    "LinearREG = LinearRegression()\n",
    "method_names[\"Linear Regression\"] = LinearREG\n",
    "\n",
    "# Adding reage regression \n",
    "params_Ridge = {'alpha': [1, 0.1,0.01,0.001,0.0001,0] ,\n",
    "                \"fit_intercept\": [True, False],\n",
    "                \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "\n",
    "\n",
    "LinearREGRedgeCV = RandomizedSearchCV(estimator = Ridge(),\n",
    "                                      param_distributions = params_Ridge,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "method_names[\"Redge\"] = LinearREGRedgeCV\n",
    "\n",
    "\n",
    "# Adding Lasso regression\n",
    "\n",
    "params_Lasso = {'alpha': [1, 0.1,0.01,0.001,0.0001,0] ,\n",
    "                \"fit_intercept\": [True, False],\n",
    "               }\n",
    "LinearREGLassoCV =  RandomizedSearchCV(estimator = Lasso(),\n",
    "                                      param_distributions = params_Lasso,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "\n",
    "method_names[\"Lasso\"] = LinearREGLassoCV\n",
    "\n",
    "\n",
    "# Adding SVR\n",
    "\n",
    "\n",
    "params_SVR = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "SupportVectorRegression =  RandomizedSearchCV(estimator = SVR(),\n",
    "                                      param_distributions = params_SVR,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "\n",
    "method_names[\"SVR\"] = SupportVectorRegression\n",
    "\n",
    "\n",
    "# Adding Decission Tree\n",
    "params_decission_tree = [{'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "                          'ccp_alpha': [0.0 , 1e-3, 1e-4, 0.5, 1.0],\n",
    "                          'max_features' : [1,2,3,4,5],\n",
    "                         'max_depth': [1,2,3,4,],\n",
    "                         'random_state':[1,4,5,100]},\n",
    "                         {'criterion': [ 'friedman_mse'],\n",
    "                          'ccp_alpha': [1.0],\n",
    "                          'max_features' : [1,2,3,4,5],\n",
    "                         'max_depth': [10,11,12,13,14],\n",
    "                         'random_state':[1,4,5,100]},\n",
    "                         {'criterion': [ 'mae'],\n",
    "                          'ccp_alpha': [0.0 , 1e-3, 1e-4, 0.5, 1.0],\n",
    "                          'max_features' : [1,2,3,4,5],\n",
    "                         'max_depth': [5,6,7,8,9],\n",
    "                         'random_state':[100]},\n",
    "                         \n",
    "                         ]\n",
    "\n",
    "#print(DecisionTreeRegressor().get_params().keys())\n",
    "\n",
    "DecissionTree =  RandomizedSearchCV(estimator = DecisionTreeRegressor(),\n",
    "                                      param_distributions = params_decission_tree,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "method_names[\"DecissionTree\"] = DecissionTree\n",
    "\n",
    "#  Adding RandomForestRegressor\n",
    "\n",
    "\n",
    "params_random_forest = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "RandomForest =  RandomizedSearchCV(estimator = RandomForestRegressor(),\n",
    "                                      param_distributions = params_random_forest,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "method_names[\"RandomForest\"] = RandomForest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file: Adrres of csv\n",
    "# methods : dictionary of methods (method_names) \n",
    "def search_models(data_file, methods, features, predictors):\n",
    "    dataobj = NutritionData(data_path=data_file)\n",
    "    model = NutritionModel(dataset=dataobj.dataset)\n",
    "    model.split_data()\n",
    "    x_val = features\n",
    "    GOOD_OUTPUT = predictors\n",
    "    r2_score = []\n",
    "    for key, value in method_names.items():\n",
    "        model.set_model(model=value)\n",
    "        if key == 'SVR':\n",
    "            score = 0\n",
    "            for item in GOOD_OUTPUT:\n",
    "                model.train_model(x_column=x_val, y_column=item)\n",
    "                score += model.test_model(x_column=x_val, y_column=item)\n",
    "                #print(score/len(GOOD_OUTPUT))\n",
    "            r2_score.append(score/len(GOOD_OUTPUT))\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            model.train_model(x_column=x_val, y_column=GOOD_OUTPUT)\n",
    "            score = model.test_model(x_column=x_val, y_column=GOOD_OUTPUT)\n",
    "            r2_score.append(score)\n",
    "            #print(score)\n",
    "\n",
    "\n",
    "        \n",
    "    data_frame_dict = {'Methods': list(method_names.keys()),\n",
    "                   'Input':[FEATURE for i in range(len(method_names.keys()))],\n",
    "                   'Output':[GOOD_OUTPUT for i in range(len(method_names.keys()))], \n",
    "                   'R^2 Score': r2_score }\n",
    "\n",
    "    df = pd.DataFrame(data=data_frame_dict)\n",
    "    print(df.head)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Vegetal Product...   0.179374  \n",
      "1  [Animal Products, Animal fats, Vegetal Product...   0.169636  \n",
      "2  [Animal Products, Animal fats, Vegetal Product...   0.178834  \n",
      "3  [Animal Products, Animal fats, Vegetal Product...   0.127943  \n",
      "4  [Animal Products, Animal fats, Vegetal Product...   0.194413  \n",
      "5  [Animal Products, Animal fats, Vegetal Product...   0.238480  >\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Vegetal Product...   0.124227  \n",
      "1  [Animal Products, Animal fats, Vegetal Product...   0.124678  \n",
      "2  [Animal Products, Animal fats, Vegetal Product...   0.124376  \n",
      "3  [Animal Products, Animal fats, Vegetal Product...   0.117719  \n",
      "4  [Animal Products, Animal fats, Vegetal Product...  -0.097686  \n",
      "5  [Animal Products, Animal fats, Vegetal Product...   0.246668  >\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Vegetal Product...   0.210790  \n",
      "1  [Animal Products, Animal fats, Vegetal Product...   0.209856  \n",
      "2  [Animal Products, Animal fats, Vegetal Product...   0.210385  \n",
      "3  [Animal Products, Animal fats, Vegetal Product...   0.191878  \n",
      "4  [Animal Products, Animal fats, Vegetal Product...   0.186187  \n",
      "5  [Animal Products, Animal fats, Vegetal Product...   0.317747  >\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Vegetal Product...   0.245428  \n",
      "1  [Animal Products, Animal fats, Vegetal Product...   0.236165  \n",
      "2  [Animal Products, Animal fats, Vegetal Product...   0.244399  \n",
      "3  [Animal Products, Animal fats, Vegetal Product...   0.211328  \n",
      "4  [Animal Products, Animal fats, Vegetal Product...   0.171732  \n",
      "5  [Animal Products, Animal fats, Vegetal Product...   0.239984  >\n"
     ]
    }
   ],
   "source": [
    "# Choose the best model for each of four dataset\n",
    "\n",
    "paths = [os.path.join(\"../Data/updated_07_06_2020\", \"Food_Supply_Quantity_kg_Data.csv\" ),\n",
    "        os.path.join(\"../Data/updated_07_06_2020\", \"Fat_Supply_Quantity_Data.csv\" ),\n",
    "        os.path.join(\"../Data/updated_07_06_2020\", \"Food_Supply_kcal_Data.csv\" ),\n",
    "        os.path.join(\"../Data/updated_07_06_2020\", \"Protein_Supply_Quantity_Data.csv\" )]\n",
    "\n",
    "\n",
    "for path in paths:\n",
    "    protein_prdiction = search_models(path,method_names,FEATURE, GOOD_OUTPUT)\n",
    "    output_path = os.path.join('../Data/outputfiles', os.path.split(path)[-1])\n",
    "    protein_prdiction.to_csv(output_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Store the best model for all datasets\n",
    "\n",
    "def store_models(data_file, model_name, features, predictors, output_dir):\n",
    "    dataobj = NutritionData(data_path=data_file)\n",
    "    model = NutritionModel(dataset=dataobj.dataset)\n",
    "    model.split_data()\n",
    "    x_val = features\n",
    "    GOOD_OUTPUT = predictors\n",
    "    model.set_model(model=value)\n",
    "    model_file = os.path.join(output_dir, os.path.split(data_file)[-1].split('.')[0] + '.pkl')\n",
    "    if key == 'SVR':\n",
    "        score = 0\n",
    "        for item in GOOD_OUTPUT:\n",
    "            model.train_model(x_column=x_val, y_column=item)\n",
    "            score += model.test_model(x_column=x_val, y_column=item)\n",
    "            print(score/len(GOOD_OUTPUT))\n",
    "            \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        model.train_model(x_column=x_val, y_column=GOOD_OUTPUT)\n",
    "        score = model.test_model(x_column=x_val, y_column=GOOD_OUTPUT)\n",
    "        model.save_model(model_file)\n",
    "        print(score)\n",
    "\n",
    "    return (os.path.split(data_file)[-1].split('.')[0], model_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24318575676273854\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   13.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2602929768880775\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30784424638319974\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.234970050407205\n"
     ]
    }
   ],
   "source": [
    "# Four models for four datasets\n",
    "model_list =[]\n",
    "for path in paths:\n",
    "    model_address  = store_models(path,method_names[\"RandomForest\"],FEATURE, GOOD_OUTPUT, '../Data/outputfiles/models')\n",
    "    model_list.append(model_address)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4420617236793843, 0.13076530409540074, 0.5579144138971044, 0.3955578905017301], [0.5269269428219676, 0.23249715525730033, 0.4730760784670881, 0.389969916260956], [0.4672009965706361, 0.15359162755182085, 0.5326745960321688, 0.42232611664871184], [0.6413811485023138, 0.09672828808652183, 0.3584873705494411, 0.14035575012790616]]\n"
     ]
    }
   ],
   "source": [
    "# Prdict output\n",
    "\n",
    "nutrition_category = []\n",
    "food_consumtion = []\n",
    "\n",
    "\n",
    "for model in model_list:\n",
    "\n",
    "    nutrition_category.append(model[0])\n",
    "    nutrition_model = NutritionModel()\n",
    "    nutrition_model.load_model(model[1])\n",
    "    food_consumtion.append(list(nutrition_model.predict([[0,0,0,1],])[0]))\n",
    "    \n",
    "print(food_consumtion)\n",
    "    \n",
    "df_dict = {'Nutrition Category': nutrition_category,\n",
    "           str(FEATURE):[[0,0,0,1] for i in range(4)],\n",
    "           str(GOOD_OUTPUT): food_consumtion\n",
    "          }\n",
    "\n",
    "df = pd.DataFrame(data= df_dict)\n",
    "df.to_csv(os.path.join('../Data/outputfiles', 'ideal_food_consumtion.csv'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 1, 3, 1, 3, 1, 3, 1, 3]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1,3] *5]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
