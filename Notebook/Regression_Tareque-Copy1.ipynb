{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Md Abdul Kadir\n",
    "\n",
    "Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importan Methodes\n",
    "# Replace the nan vale with mean, median, or most frequent value\n",
    "def replaceNaN(dataframe, replaceby = \"mean\"):\n",
    "    if (replaceby == \"mean\"):\n",
    "        return dataframe.fillna(dataframe.mean())\n",
    "    \n",
    "    elif (replaceby == \"median\"):\n",
    "        return dataframe.fillna(dataframe.median())\n",
    "    \n",
    "    elif (replaceby == \"mostfrq\"):\n",
    "        return dataframe.fillna(dataframe.mode().iloc[0])\n",
    "    \n",
    "    else:return dataframe.dropna()\n",
    "    \n",
    "# Replce any nonnumaric char from a column.    \n",
    "def replce_char(dataframe,collumn, char=r'^<'):\n",
    "    dataframe[collumn] =  dataframe[collumn].replace(regex=char, value='')\n",
    "    dataframe[collumn] = pd.to_numeric(dataframe[collumn],errors='coerce')\n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "    \n",
    "# Scale the data using standard scaler or max min scaler. Menstion the names to scale. \n",
    "def scale(dataframe, coulumns, scaler=\"ss\"):\n",
    "    if (scaler == \"mm\"):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        dataframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "        return dataframe\n",
    "    elif (scaler == \"ss\"):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        datqframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "        return dataframe\n",
    "    \n",
    "    else:return dataframe\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dtasets\n",
    "\n",
    "# Load Food Supply Data\n",
    "\n",
    "Food_Supply_DF = pd.read_csv(\"../Data/updated_07_06_2020/Food_Supply_Quantity_kg_Data.csv\")\n",
    "Food_Supply_DF = replaceNaN(Food_Supply_DF, replaceby=\"mostfrq\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcoholic Beverages', 'Animal fats', 'Animal Products',\n",
      "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
      "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
      "       'Milk - Excluding Butter', 'Miscellaneous', 'Offals', 'Oilcrops',\n",
      "       'Pulses', 'Spices', 'Starchy Roots', 'Stimulants', 'Sugar & Sweeteners',\n",
      "       'Sugar Crops', 'Treenuts', 'Vegetable Oils', 'Vegetables',\n",
      "       'Vegetal Products', 'Obesity', 'Undernourished', 'Confirmed', 'Deaths',\n",
      "       'Recovered', 'Active'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "##Standard Scaler \n",
    "NOT_IPMORTANT_COLUMNS = [\"Country\", 'Unit (all except Population)', 'Population']\n",
    "\n",
    "clm = Food_Supply_DF.columns.drop(NOT_IPMORTANT_COLUMNS)\n",
    "print(clm)\n",
    "\n",
    "Food_Supply_DF = replce_char(Food_Supply_DF,\"Undernourished\", char=r'^<')\n",
    "scaled_df = scale(Food_Supply_DF, clm, scaler=\"mm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise data\n",
    "scaled_df = scaled_df.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "# scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple regression model for 1 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosse training input and output\n",
    "#XY = scaled_df[['Undernourished','Obesity' ]]\n",
    "#XY.plot.scatter(x = 'Undernourished', y ='Obesity')\n",
    "\n",
    "FEATURE_CLS = ['Obesity', 'Undernourished', 'Deaths','Recovered','Active','Confirmed']\n",
    "FEATURE = ['Obesity', 'Undernourished', 'Deaths','Recovered' ]\n",
    "\n",
    "ALL_OUTPUT = ['Alcoholic Beverages', 'Animal Products', 'Animal fats',\n",
    "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
    "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
    "       'Milk - Excluding Butter', 'Offals', 'Oilcrops', 'Pulses', 'Spices',\n",
    "       'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners',\n",
    "       'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables',\n",
    "       'Miscellaneous']\n",
    "GOOD_OUTPUT=['Animal Products', 'Animal fats','Vegetal Products','Vegetable Oils' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide trian and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(scaled_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25565351710261847, -2.8834136950782634, 0.22026646186220522]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installation\\anaconda\\envs\\dl_env\\lib\\site-packages\\sklearn\\base.py:426: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  warnings.warn(\"The default value of multioutput (not exposed in \"\n",
      "D:\\Installation\\anaconda\\envs\\dl_env\\lib\\site-packages\\sklearn\\base.py:426: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  warnings.warn(\"The default value of multioutput (not exposed in \"\n",
      "D:\\Installation\\anaconda\\envs\\dl_env\\lib\\site-packages\\sklearn\\base.py:426: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  warnings.warn(\"The default value of multioutput (not exposed in \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold \n",
    "X = pd.DataFrame(scaled_df[FEATURE_CLS])\n",
    "y = pd.DataFrame(scaled_df[GOOD_OUTPUT])\n",
    "model = LinearRegression()\n",
    "scores = []\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "for i, (train, test) in enumerate(kfold.split(X, y)):\n",
    "    model.fit(X.iloc[train,:], y.iloc[train,:])\n",
    "    score = model.score(X.iloc[test,:], y.iloc[test,:])\n",
    "    scores.append(score)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def Regression(features, response, data, method = LinearRegression()):\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    return model.fit(X, Y)\n",
    "    \n",
    "    \n",
    "    \n",
    "def TestScore(features, response, data, model):\n",
    "    print('Output: ', response)\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    return model.score(X,Y)\n",
    "    \n",
    "def PlotRegression(features, response, data, model):\n",
    "    import matplotlib.pyplot as plt\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(X, Y, s=10)\n",
    "    plt.plot(X, y_pred, color='r')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = Regression(FEATURE_CLS, GOOD_OUTPUT, train_set, method = linear_model.Lasso(alpha=0.1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  ['Animal Products', 'Animal fats', 'Vegetal Products', 'Vegetable Oils']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installation\\anaconda\\envs\\dl_env\\lib\\site-packages\\sklearn\\base.py:426: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  warnings.warn(\"The default value of multioutput (not exposed in \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.405427453754149"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestScore(FEATURE_CLS, GOOD_OUTPUT,test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PlotRegression(FEATURE_CLS, ALL_OUTPUT  ,tra in_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  Alcoholic Beverages\n",
      "R^2 :  0.012966420549500035\n",
      "Output:  Animal Products\n",
      "R^2 :  0.326676303223286\n",
      "Output:  Animal fats\n",
      "R^2 :  0.10012787125844702\n",
      "Output:  Aquatic Products, Other\n",
      "R^2 :  -46.73291959180186\n",
      "Output:  Cereals - Excluding Beer\n",
      "R^2 :  0.3306840033819963\n",
      "Output:  Eggs\n",
      "R^2 :  0.2878016465935943\n",
      "Output:  Fish, Seafood\n",
      "R^2 :  -0.1800763222310393\n",
      "Output:  Fruits - Excluding Wine\n",
      "R^2 :  -0.0011452530491429247\n",
      "Output:  Meat\n",
      "R^2 :  0.14936677556507216\n",
      "Output:  Milk - Excluding Butter\n",
      "R^2 :  0.17457727080602814\n",
      "Output:  Offals\n",
      "R^2 :  0.019803438466795664\n",
      "Output:  Oilcrops\n",
      "R^2 :  -0.7777524802263447\n",
      "Output:  Pulses\n",
      "R^2 :  0.23487111307332043\n",
      "Output:  Spices\n",
      "R^2 :  0.042880680231890296\n",
      "Output:  Starchy Roots\n",
      "R^2 :  0.1524583645950104\n",
      "Output:  Stimulants\n",
      "R^2 :  -0.0661786555185031\n",
      "Output:  Sugar Crops\n",
      "R^2 :  -0.006897764958550434\n",
      "Output:  Sugar & Sweeteners\n",
      "R^2 :  0.0961219883694462\n",
      "Output:  Treenuts\n",
      "R^2 :  0.016051722632956178\n",
      "Output:  Vegetal Products\n",
      "R^2 :  0.3267266344131676\n",
      "Output:  Vegetable Oils\n",
      "R^2 :  -0.036034529252650715\n",
      "Output:  Vegetables\n",
      "R^2 :  0.11997198761153671\n",
      "Output:  Miscellaneous\n",
      "R^2 :  -0.4294701641663228\n"
     ]
    }
   ],
   "source": [
    "for cls in ALL_OUTPUT:\n",
    "    model = Regression(FEATURE, cls, train_set, method = linear_model.Lasso(alpha=0.5) )\n",
    "    print('R^2 : ', TestScore(FEATURE, cls,test_set, model))\n",
    "    #PlotRegression(FEATURE, cls ,test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import linear_model\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE])\n",
    "    #print(X_train_transformed)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    \n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for i, (train, test) in enumerate(kfold.split(X, y)):\n",
    "        model.fit(X.iloc[train,:], y.iloc[train,:])\n",
    "        score = model.score(X.iloc[test,:], y.iloc[test,:])\n",
    "        scores.append(score)\n",
    "    print(scores)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(max_depth=2)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE_CLS])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE_CLS])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model =  SVR(C=1.0, epsilon=0.1)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE_CLS])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE_CLS])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Dataset and model class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset class\n",
    "class NutritionData():\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        dataframe = pd.read_csv(self.data_path)\n",
    "        dataframe = self.__replaceNaN(dataframe, replaceby=\"mostfrq\")\n",
    "        \n",
    "        ##Standard Scaler \n",
    "        NOT_IPMORTANT_COLUMNS = [\"Country\", 'Unit (all except Population)', 'Population']\n",
    "\n",
    "        clm = dataframe.columns.drop(NOT_IPMORTANT_COLUMNS)\n",
    "\n",
    "        dataframe = self.__replace_char(dataframe, \"Undernourished\", char=r'^<')\n",
    "        scaled_df = self.__scale(dataframe, clm, scaler=\"mm\")\n",
    "        scaled_df = scaled_df.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "\n",
    "        self.dataset = scaled_df\n",
    "        \n",
    "    \n",
    "        # Importan Methodes\n",
    "    # Replace the nan vale with mean, median, or most frequent value\n",
    "    def __replaceNaN(self, dataframe, replaceby = \"mean\"):\n",
    "        if (replaceby == \"mean\"):\n",
    "            return dataframe.fillna(dataframe.mean())\n",
    "\n",
    "        elif (replaceby == \"median\"):\n",
    "            return dataframe.fillna(dataframe.median())\n",
    "\n",
    "        elif (replaceby == \"mostfrq\"):\n",
    "            return dataframe.fillna(dataframe.mode().iloc[0])\n",
    "\n",
    "        else:return dataframe.dropna()\n",
    "        \n",
    "        \n",
    "\n",
    "    # Replce any nonnumaric char from a column.    \n",
    "    def __replace_char(self, dataframe, collumn, char=r'^<'):\n",
    "        \n",
    "        dataframe[collumn] =  dataframe[collumn].replace(regex=char, value='')\n",
    "        dataframe[collumn] = pd.to_numeric(dataframe[collumn],errors='coerce')\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "\n",
    "    # Scale the data using standard scaler or max min scaler. Menstion the names to scale. \n",
    "    def __scale(self, dataframe, coulumns, scaler=\"ss\"):\n",
    "        \n",
    "        if (scaler == \"mm\"):\n",
    "            from sklearn.preprocessing import MinMaxScaler\n",
    "            scaler = MinMaxScaler()\n",
    "            dataframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "            return dataframe\n",
    "        elif (scaler == \"ss\"):\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            datqframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "            return dataframe\n",
    "\n",
    "        else:return dataframe\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalizing class to test and train all the models\n",
    "class NutritionModel():\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.model = None\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "        \n",
    "        \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        # splits the dataset in train and test set\n",
    "        self.train_set, self.test_set  = train_test_split(self.dataset, test_size=test_size, random_state=42)\n",
    "      \n",
    "    \n",
    "    def set_model(self, model):\n",
    "        # setting up the model\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "    def save_model(self, pkl_filename='model.pkl'):\n",
    "        with open(pkl_filename, 'wb') as file:\n",
    "            pickle.dump(self.model, file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def load_model(self, pkl_filename='model.pkl'):\n",
    "        with open(pkl_filename, 'rb') as file:\n",
    "            self.model = pickle.load(file)\n",
    "    \n",
    "        \n",
    "    \n",
    "    def train_model(self, x_column, y_column):\n",
    "        #traing the model\n",
    "        # input arg: x column name, y column names\n",
    "        self.model.fit(self.train_set[x_column], self.train_set[y_column])\n",
    "    \n",
    "    \n",
    "    def test_model(self, x_column, y_column): \n",
    "        score = self.model.score(self.test_set[x_column], self.test_set[y_column])\n",
    "        return score\n",
    "    \n",
    "    \n",
    "    def predict_model(self, X):\n",
    "        \n",
    "        predicted = self.model.predict(X)\n",
    "        return predicted\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_CLS = ['Obesity', 'Undernourished', 'Deaths','Recovered','Active','Confirmed']\n",
    "FEATURE = ['Obesity', 'Undernourished', 'Deaths','Recovered' ]\n",
    "\n",
    "ALL_OUTPUT = ['Alcoholic Beverages', 'Animal Products', 'Animal fats',\n",
    "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
    "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
    "       'Milk - Excluding Butter', 'Offals', 'Oilcrops', 'Pulses', 'Spices',\n",
    "       'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners',\n",
    "       'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables',\n",
    "       'Miscellaneous']\n",
    "GOOD_OUTPUT=['Animal Products', 'Animal fats','Vegetal Products','Vegetable Oils' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())\n",
    "#Parameters currently in use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1, refit=True)\n",
    "# Fit the random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Log file is ../log/linear_regression/log.txt.\n"
     ]
    }
   ],
   "source": [
    "log_path = '../log/random_forest/'\n",
    "data_root = '../Data/updated_04_07_2020/Food_Supply_Quantity_kg_Data.csv'\n",
    "\n",
    "# change here\n",
    "data_file = \"Food_Supply_Quantity_kg_Data.csv\"\n",
    "log_file = log_path + 'log.txt'\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Print arguments\n",
    "logger.info('Log file is %s.' % log_file)\n",
    "# logger.info('Data path is %s.' % data_path)\n",
    "# logger.info('Export path is %s.' % xp_path)\n",
    "\n",
    "data_path = data_root + data_file\n",
    "\n",
    "\n",
    "if not os.path.exists(data_file.split('.')[0]):\n",
    "    model_dirs = log_path + data_file.split('.')[0]\n",
    "    os.makedirs(model_dirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data path is ../Data/updated_07_06_2020/Food_Supply_Quantity_kg_Data.csv. \n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.058859047554293165\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3875310149996316\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   16.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11905740451014302\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-28.956100284330454\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3385219766292279\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   16.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1730374171277943\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0655114645998689\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1287214727181336\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07611992406507029\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1464143590494429\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024551184188913777\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0621151510894338\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23890271257994555\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5101917905049733\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3839375208140905\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16136756572425123\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15669869264521652\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.052500638852764014\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   17.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049876373755234904\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   19.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37355179773194447\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   19.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07509543175077926\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   16.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022522308632970556\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   21.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7610835975049794\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "dataobj = NutritionData(data_path=data_path) # creating dataset\n",
    "logger.info('Data path is %s. ', data_path)\n",
    "# creating model classes\n",
    "model = NutritionModel(dataset=dataobj.dataset)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model.set_model(model=rf_random)\n",
    "model.split_data()\n",
    "\n",
    "\n",
    "for y_val in ALL_OUTPUT:\n",
    "    x_val = FEATURE\n",
    "    model.train_model(x_column=x_val, y_column=y_val)\n",
    "    score = model.test_model(x_column=x_val, y_column=y_val)\n",
    "    model.save_model(pkl_filename=os.path.join(model_dirs, y_val+'.pkl'))\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()\n",
    "model.load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
