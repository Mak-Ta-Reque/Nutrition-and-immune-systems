{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Md Abdul Kadir\n",
    "\n",
    "Linear Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Dataset and model class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset class\n",
    "class NutritionData:\n",
    "    \n",
    "    def __init__(self, data_path=None):\n",
    "        self.GOOD_OUTPUT =['Animal Products', 'Animal fats', 'Meat', 'Cereals - Excluding Beer','Vegetables','Vegetal Products','Vegetable Oils', 'Oilcrops' ]\n",
    "        self.NOT_IPMORTANT_COLUMNS  = [\"Country\", 'Unit (all except Population)', 'Population', \n",
    "                                      'Obesity', 'Undernourished', 'Confirmed', 'Deaths','Recovered', 'Active',\n",
    "                                      'Alcoholic Beverages',\n",
    "           'Aquatic Products, Other', 'Eggs',\n",
    "           'Fish, Seafood', 'Fruits - Excluding Wine',\n",
    "           'Milk - Excluding Butter', 'Offals','Pulses', 'Spices',\n",
    "           'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners',\n",
    "           'Treenuts',\n",
    "           'Miscellaneous']\n",
    "        \n",
    "        if data_path != None:\n",
    "            self.data_path = data_path\n",
    "            dataframe = pd.read_csv(self.data_path)\n",
    "            dataframe = self.__replaceNaN(dataframe, replaceby=\"mostfrq\")\n",
    "\n",
    "            ##Standard Scaler \n",
    "            #NOT_IPMORTANT_COLUMNS = [\"Country\", 'Unit (all except Population)', 'Population', \n",
    "            #                       'Obesity', 'Undernourished', 'Confirmed', 'Deaths','Recovered', 'Active']\n",
    "\n",
    "            \n",
    "\n",
    "            clm = dataframe.columns.drop(self.NOT_IPMORTANT_COLUMNS)\n",
    "\n",
    "            dataframe = self.__replace_char(dataframe, \"Undernourished\", char=r'^<')\n",
    "            scaled_df, self.scaler   = self.__scale(dataframe, clm, scaler=\"mm\")\n",
    "            scaled_df = scaled_df.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "\n",
    "            self.dataset = scaled_df\n",
    "        \n",
    "    \n",
    "        # Importan Methodes\n",
    "    # Replace the nan vale with mean, median, or most frequent value\n",
    "    def __replaceNaN(self, dataframe, replaceby = \"mean\"):\n",
    "        if (replaceby == \"mean\"):\n",
    "            return dataframe.fillna(dataframe.mean())\n",
    "\n",
    "        elif (replaceby == \"median\"):\n",
    "            return dataframe.fillna(dataframe.median())\n",
    "\n",
    "        elif (replaceby == \"mostfrq\"):\n",
    "            return dataframe.fillna(dataframe.mode().iloc[0])\n",
    "\n",
    "        else:return dataframe.dropna()\n",
    "        \n",
    "        \n",
    "\n",
    "    # Replce any nonnumaric char from a column.    \n",
    "    def __replace_char(self, dataframe, collumn, char=r'^<'):\n",
    "        \n",
    "        dataframe[collumn] =  dataframe[collumn].replace(regex=char, value='')\n",
    "        dataframe[collumn] = pd.to_numeric(dataframe[collumn],errors='coerce')\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "\n",
    "    # Scale the data using standard scaler or max min scaler. Menstion the names to scale. \n",
    "    def __scale(self, dataframe, coulumns, scaler=\"ss\"):\n",
    "        \n",
    "        if (scaler == \"mm\"):\n",
    "            from sklearn.preprocessing import MinMaxScaler\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(dataframe[coulumns])\n",
    "            dataframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "            return dataframe, scaler\n",
    "        elif (scaler == \"ss\"):\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(dataframe[coulumns])\n",
    "            datqframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "            return dataframe, scaler\n",
    "\n",
    "        else:return dataframe, scaler\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalizing class to test and train all the models\n",
    "class NutritionModel:\n",
    "    \n",
    "    def __init__(self, dataset=None):\n",
    "        self.dataset = dataset\n",
    "        self.model = None\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "        \n",
    "        \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        # splits the dataset in train and test set\n",
    "        self.train_set, self.test_set  = train_test_split(self.dataset, test_size=test_size, random_state=42)\n",
    "      \n",
    "    \n",
    "    def set_model(self, model):\n",
    "        # setting up the model\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "    def save_model(self, pkl_filename='model.pkl'):\n",
    "        with open(pkl_filename, 'wb') as file:\n",
    "            pickle.dump(self.model, file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def load_model(self, pkl_filename='model.pkl'):\n",
    "        with open(pkl_filename, 'rb') as file:\n",
    "            self.model = pickle.load(file)\n",
    "    \n",
    "        \n",
    "    \n",
    "    def train_model(self, x_column, y_column):\n",
    "        #traing the model\n",
    "        # input arg: x column name, y column names\n",
    "        self.model.fit(self.train_set[x_column], self.train_set[y_column])\n",
    "    \n",
    "    \n",
    "    def test_model(self, x_column, y_column): \n",
    "        score = self.model.score(self.test_set[x_column], self.test_set[y_column])\n",
    "        return score\n",
    "    \n",
    "    \n",
    "    def predict(self, X):     \n",
    "        return self.model.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_CLS = ['Obesity', 'Undernourished', 'Deaths','Recovered','Active','Confirmed']\n",
    "FEATURE = ['Obesity', 'Undernourished', 'Deaths','Recovered' ]\n",
    "\n",
    "ALL_OUTPUT = ['Alcoholic Beverages', 'Animal Products', 'Animal fats',\n",
    "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
    "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
    "       'Milk - Excluding Butter', 'Offals', 'Oilcrops', 'Pulses', 'Spices',\n",
    "       'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners',\n",
    "       'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables',\n",
    "       'Miscellaneous']\n",
    "#GOOD_OUTPUT=['Animal Products', 'Cereals - Excluding Beer', 'Oilcrops', 'Meat','Animal fats','Vegetal Products','Vegetable Oils' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())\n",
    "#Parameters currently in use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1, refit=True)\n",
    "# Fit the random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.022024923937873753\n"
     ]
    }
   ],
   "source": [
    "# Tareque \n",
    "\n",
    "# Create class to that take a csv file as an input\n",
    "# Return output prediction \n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "dataobj = NutritionData(data_path=data_path) # creating dataset\n",
    "# creating model classes\n",
    "model = NutritionModel(dataset=dataobj.dataset)\n",
    "\n",
    "model.set_model(model=rf_random)\n",
    "model.split_data()\n",
    "\n",
    "x_val = FEATURE\n",
    "model.train_model(x_column=x_val, y_column=dataobj.GOOD_OUTPUT)\n",
    "score = model.test_model(x_column=x_val, y_column=dataobj.GOOD_OUTPUT)\n",
    "\n",
    "print(score)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "method_names = {}\n",
    "# Adding linear regression\n",
    "LinearREG = LinearRegression()\n",
    "method_names[\"Linear Regression\"] = LinearREG\n",
    "\n",
    "# Adding reage regression \n",
    "params_Ridge = {'alpha': [1, 0.1,0.01,0.001,0.0001,0] ,\n",
    "                \"fit_intercept\": [True, False],\n",
    "                \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "\n",
    "\n",
    "LinearREGRedgeCV = RandomizedSearchCV(estimator = Ridge(),\n",
    "                                      param_distributions = params_Ridge,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "method_names[\"Redge\"] = LinearREGRedgeCV\n",
    "\n",
    "\n",
    "# Adding Lasso regression\n",
    "\n",
    "params_Lasso = {'alpha': [1, 0.1,0.01,0.001,0.0001,0] ,\n",
    "                \"fit_intercept\": [True, False],\n",
    "               }\n",
    "LinearREGLassoCV =  RandomizedSearchCV(estimator = Lasso(),\n",
    "                                      param_distributions = params_Lasso,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "\n",
    "method_names[\"Lasso\"] = LinearREGLassoCV\n",
    "\n",
    "\n",
    "# Adding SVR\n",
    "\n",
    "\n",
    "params_SVR = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "SupportVectorRegression =  RandomizedSearchCV(estimator = SVR(),\n",
    "                                      param_distributions = params_SVR,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "\n",
    "method_names[\"SVR\"] = SupportVectorRegression\n",
    "\n",
    "\n",
    "# Adding Decission Tree\n",
    "params_decission_tree = [{'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "                          'ccp_alpha': [0.0 , 1e-3, 1e-4, 0.5, 1.0],\n",
    "                          'max_features' : [1,2,3,4,5],\n",
    "                         'max_depth': [1,2,3,4,],\n",
    "                         'random_state':[1,4,5,100]},\n",
    "                         {'criterion': [ 'friedman_mse'],\n",
    "                          'ccp_alpha': [1.0],\n",
    "                          'max_features' : [1,2,3,4,5],\n",
    "                         'max_depth': [10,11,12,13,14],\n",
    "                         'random_state':[1,4,5,100]},\n",
    "                         {'criterion': [ 'mae'],\n",
    "                          'ccp_alpha': [0.0 , 1e-3, 1e-4, 0.5, 1.0],\n",
    "                          'max_features' : [1,2,3,4,5],\n",
    "                         'max_depth': [5,6,7,8,9],\n",
    "                         'random_state':[100]},\n",
    "                         \n",
    "                         ]\n",
    "\n",
    "#print(DecisionTreeRegressor().get_params().keys())\n",
    "\n",
    "DecissionTree =  RandomizedSearchCV(estimator = DecisionTreeRegressor(),\n",
    "                                      param_distributions = params_decission_tree,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "method_names[\"DecissionTree\"] = DecissionTree\n",
    "\n",
    "#  Adding RandomForestRegressor\n",
    "\n",
    "\n",
    "params_random_forest = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "RandomForest =  RandomizedSearchCV(estimator = RandomForestRegressor(),\n",
    "                                      param_distributions = params_random_forest,\n",
    "                                      n_iter = 10,\n",
    "                                      cv = 5, verbose=2,\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1, refit=True)\n",
    "\n",
    "\n",
    "method_names[\"RandomForest\"] = RandomForest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file: Adrres of csv\n",
    "# methods : dictionary of methods (method_names) \n",
    "def search_models(data_file, methods, features, predictors):\n",
    "    dataobj = NutritionData(data_path=data_file)\n",
    "    model = NutritionModel(dataset=dataobj.dataset)\n",
    "    model.split_data()\n",
    "    x_val = features\n",
    "    GOOD_OUTPUT = predictors\n",
    "    r2_score = []\n",
    "    for key, value in method_names.items():\n",
    "        model.set_model(model=value)\n",
    "        if key == 'SVR':\n",
    "            score = 0\n",
    "            for item in predictors:\n",
    "                model.train_model(x_column=x_val, y_column=item)\n",
    "                score += model.test_model(x_column=x_val, y_column=item)\n",
    "                #print(score/len(GOOD_OUTPUT))\n",
    "            r2_score.append(score/len(predictors))\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            model.train_model(x_column=x_val, y_column=predictors)\n",
    "            score = model.test_model(x_column=x_val, y_column=predictors)\n",
    "            r2_score.append(score)\n",
    "            #print(score)\n",
    "\n",
    "\n",
    "        \n",
    "    data_frame_dict = {'Methods': list(method_names.keys()),\n",
    "                   'Input':[FEATURE for i in range(len(method_names.keys()))],\n",
    "                   'Output':[GOOD_OUTPUT for i in range(len(method_names.keys()))], \n",
    "                   'R^2 Score': r2_score }\n",
    "\n",
    "    df = pd.DataFrame(data=data_frame_dict)\n",
    "    print(df.head)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  50 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   20.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   36.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   40.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   25.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   40.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  50 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Meat, Cereals -...   0.067471  \n",
      "1  [Animal Products, Animal fats, Meat, Cereals -...   0.056346  \n",
      "2  [Animal Products, Animal fats, Meat, Cereals -...   0.093202  \n",
      "3  [Animal Products, Animal fats, Meat, Cereals -...   0.054478  \n",
      "4  [Animal Products, Animal fats, Meat, Cereals -...   0.063413  \n",
      "5  [Animal Products, Animal fats, Meat, Cereals -...   0.047856  >\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   34.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   22.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   24.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   22.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Meat, Cereals -...   0.087766  \n",
      "1  [Animal Products, Animal fats, Meat, Cereals -...   0.086688  \n",
      "2  [Animal Products, Animal fats, Meat, Cereals -...   0.081626  \n",
      "3  [Animal Products, Animal fats, Meat, Cereals -...   0.155828  \n",
      "4  [Animal Products, Animal fats, Meat, Cereals -...   0.097889  \n",
      "5  [Animal Products, Animal fats, Meat, Cereals -...   0.175038  >\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  50 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   49.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   38.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   53.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Meat, Cereals -...   0.160540  \n",
      "1  [Animal Products, Animal fats, Meat, Cereals -...   0.142374  \n",
      "2  [Animal Products, Animal fats, Meat, Cereals -...   0.155263  \n",
      "3  [Animal Products, Animal fats, Meat, Cereals -...   0.167210  \n",
      "4  [Animal Products, Animal fats, Meat, Cereals -...   0.135471  \n",
      "5  [Animal Products, Animal fats, Meat, Cereals -...   0.222005  >\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  50 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   34.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   29.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   40.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   39.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   35.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              Methods                                         Input  \\\n",
      "0  Linear Regression  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "1              Redge  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "2              Lasso  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "3                SVR  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "4      DecissionTree  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "5       RandomForest  [Obesity, Undernourished, Deaths, Recovered]   \n",
      "\n",
      "                                              Output  R^2 Score  \n",
      "0  [Animal Products, Animal fats, Meat, Cereals -...   0.200632  \n",
      "1  [Animal Products, Animal fats, Meat, Cereals -...   0.172591  \n",
      "2  [Animal Products, Animal fats, Meat, Cereals -...   0.169464  \n",
      "3  [Animal Products, Animal fats, Meat, Cereals -...   0.157113  \n",
      "4  [Animal Products, Animal fats, Meat, Cereals -...   0.143764  \n",
      "5  [Animal Products, Animal fats, Meat, Cereals -...   0.206798  >\n"
     ]
    }
   ],
   "source": [
    "# Choose the best model for each of four dataset\n",
    "\n",
    "paths = [os.path.join(\"../Data/updated_07_06_2020\", \"Food_Supply_Quantity_kg_Data.csv\" ),\n",
    "        os.path.join(\"../Data/updated_07_06_2020\", \"Fat_Supply_Quantity_Data.csv\" ),\n",
    "        os.path.join(\"../Data/updated_07_06_2020\", \"Food_Supply_kcal_Data.csv\" ),\n",
    "        os.path.join(\"../Data/updated_07_06_2020\", \"Protein_Supply_Quantity_Data.csv\" )]\n",
    "\n",
    "\n",
    "\n",
    "output = NutritionData().GOOD_OUTPUT\n",
    "for path in paths:\n",
    "    protein_prdiction = search_models(path,method_names,FEATURE, output)\n",
    "    output_path = os.path.join('../Data/outputfiles_reduced', os.path.split(path)[-1])\n",
    "    protein_prdiction.to_csv(output_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Store the best model for all datasets\n",
    "\n",
    "def store_models(data_file, model_name, method_name, features, predictors, output_dir):\n",
    "    dataobj = NutritionData(data_path=data_file)\n",
    "    model = NutritionModel(dataset=dataobj.dataset)\n",
    "    model.split_data()\n",
    "    x_val = features\n",
    "    GOOD_OUTPUT = predictors\n",
    "    model.set_model(model=model_name)\n",
    "    model_file = os.path.join(output_dir, os.path.split(data_file)[-1].split('.')[0] + '.pkl')\n",
    "\n",
    "    if method_name == 'SVR':\n",
    "        score = 0\n",
    "        for item in predictors:\n",
    "            model.train_model(x_column=x_val, y_column=item)\n",
    "            score += model.test_model(x_column=x_val, y_column=item)\n",
    "            print(score/len(predictors))\n",
    "            \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        model.train_model(x_column=x_val, y_column=predictors)\n",
    "        score = model.test_model(x_column=x_val, y_column=predictors)\n",
    "        ideal_prediction = model.predict([[0,0,0,1],])\n",
    "        ideal_prediction = dataobj.scaler.inverse_transform(ideal_prediction)\n",
    "        model.save_model(model_file)\n",
    "        print(score)\n",
    "        \n",
    "    \n",
    "\n",
    "    return (os.path.split(data_file)[-1].split('.')[0], model_file, ideal_prediction)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,7) (8,) (1,7) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-3a603bb9274f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel_address\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstore_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RandomForest\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RandomForest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGOOD_OUTPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../Data/outputfiles_reduced/models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-b380cf151bb5>\u001b[0m in \u001b[0;36mstore_models\u001b[0;34m(data_file, model_name, method_name, features, predictors, output_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mideal_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mideal_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mideal_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-venv/ds/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,7) (8,) (1,7) "
     ]
    }
   ],
   "source": [
    "# Four models for four datasets\n",
    "model_list =[]\n",
    "for path in paths:\n",
    "    model_address  = store_models(path,method_names[\"RandomForest\"],\"RandomForest\", FEATURE, output, '../Data/outputfiles_reduced/models')\n",
    "    model_list.append(model_address)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.261095347453607, 0.5329404672301871, 4.207428179801412, 0.13791637435851045, 10.658460749013324, 0.5624469485995601, 2.450844151444623, 6.067777304138026, 4.298095257579506, 3.814721057125187, 0.6398104946139958, 0.15284596217941673, 1.1707663398327481, 0.6623256566306277, 0.07436803616175217, 4.748302788457057, 0.07779653219007089, 3.03231451989898, 0.4957354267294556, 0.4596981691884802, 0.8940779285311996, 7.431964064700125, 28.950063390031055], [0.0082264428016428, 22.67102909641221, 3.570607155915938, 0.0049350189127049405, 3.9780535205712195, 1.2228166019726598, 1.7765407176365324, 0.49463392608694423, 11.794091900212168, 0.10303062833270141, 3.8743494033815047, 0.09928907567113021, 1.791557568288561, 0.4084227259983803, 0.18452021151234035, 0.551611737539474, 0.18098144255610046, 0.007675940693057114, 0.014303851434704118, 2.22077587877375, 24.22802178791316, 15.009182966198178, 0.28049252939975533], [1.550231608830507, 10.65570929200709, 1.0858511758127498, 0.04112379708775701, 19.398315668458906, 0.5568839004120879, 1.1902822872758778, 2.0479143729008737, 4.829626262018166, 2.7867917153622925, 0.2363229473779899, 0.11156536763591793, 0.8291246994946659, 1.493024048737938, 0.10576574829756043, 4.378964022073179, 0.11910982653763551, 0.26222718427053465, 2.6882610345082427, 0.79985285760513, 36.39849147251299, 5.02514052119264, 0.8715127334323434], [0.4330000000000036, 21.742900000000116, 0.06206666666666712, 0.37846666666666934, 18.374099999999892, 1.962799999999972, 6.0061999999999705, 0.4603333333333316, 8.932266666666752, 3.547300000000032, 0.8568333333333272, 2.8578333333333723, 0.7757666666666685, 0.11229999999999937, 0.7080333333333372, 0.3801333333333347, 0.017333333333333353, 0.035999999999999754, 0.23983333333333332, 28.25463333333346, 0.012633333333333345, 3.791966666666691, 0.05726666666666693]]\n"
     ]
    }
   ],
   "source": [
    "# Prdict output\n",
    "\n",
    "nutrition_category = []\n",
    "food_consumtion = []\n",
    "\n",
    "\n",
    "for model in model_list:\n",
    "    \n",
    "    nutrition_category.append(model[0])\n",
    "    #nutrition_model = NutritionModel()\n",
    "    #nutrition_model.load_model(model[1])\n",
    "    food_consumtion.append(list(model[2][0]))\n",
    "    \n",
    "print(food_consumtion)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "df_dict = {'Nutrition Category': nutrition_category,\n",
    "           str(FEATURE):[[0,0,0,1] for i in range(4)],\n",
    "           str(ooutput): food_consumtion\n",
    "          }\n",
    "\n",
    "df = pd.DataFrame(data= df_dict)\n",
    "df.to_csv(os.path.join('../Data/outputfiles', 'ideal_food_consumtion.csv'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 1, 3, 1, 3, 1, 3, 1, 3]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1,3] *5]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
