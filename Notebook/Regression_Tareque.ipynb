{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Md Abdul Kadir\n",
    "\n",
    "Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importan Methodes\n",
    "# Replace the nan vale with mean, median, or most frequent value\n",
    "def replaceNaN(dataframe, replaceby = \"mean\"):\n",
    "    if (replaceby == \"mean\"):\n",
    "        return dataframe.fillna(dataframe.mean())\n",
    "    \n",
    "    elif (replaceby == \"median\"):\n",
    "        return dataframe.fillna(dataframe.median())\n",
    "    \n",
    "    elif (replaceby == \"mostfrq\"):\n",
    "        return dataframe.fillna(dataframe.mode().iloc[0])\n",
    "    \n",
    "    else:return dataframe.dropna()\n",
    "    \n",
    "# Replce any nonnumaric char from a column.    \n",
    "def replce_char(dataframe,collumn, char=r'^<'):\n",
    "    dataframe[collumn] =  dataframe[collumn].replace(regex=char, value='')\n",
    "    dataframe[collumn] = pd.to_numeric(dataframe[collumn],errors='coerce')\n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "    \n",
    "# Scale the data using standard scaler or max min scaler. Menstion the names to scale. \n",
    "def scale(dataframe, coulumns, scaler=\"ss\"):\n",
    "    if (scaler == \"mm\"):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        dataframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "        return dataframe\n",
    "    elif (scaler == \"ss\"):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        datqframe[coulumns] = scaler.fit_transform(dataframe[coulumns])\n",
    "        return dataframe\n",
    "    \n",
    "    else:return dataframe\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dtasets\n",
    "\n",
    "# Load Protein Supply Data\n",
    "\n",
    "Protein_Supply_DF = pd.read_csv(\"../Data/Protein_Supply_Quantity_Data.csv\")\n",
    "Protein_Supply_DF = replaceNaN(Protein_Supply_DF, replaceby=\"mostfrq\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Standard Scaler \n",
    "NOT_IPMORTANT_COLUMNS = [\"Country\", 'Unit (all except Population)', 'Population']\n",
    "\n",
    "clm = Protein_Supply_DF.columns.drop(NOT_IPMORTANT_COLUMNS)\n",
    "\n",
    "Protein_Supply_DF = replce_char(Protein_Supply_DF,\"Undernourished\", char=r'^<')\n",
    "scaled_df = scale(Protein_Supply_DF, clm, scaler=\"mm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise data\n",
    "scaled_df = scaled_df.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple regression model for 1 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosse training input and output\n",
    "#XY = scaled_df[['Undernourished','Obesity' ]]\n",
    "#XY.plot.scatter(x = 'Undernourished', y ='Obesity')\n",
    "\n",
    "FEATURE_CLS = ['Obesity', 'Undernourished', 'Deaths','Recovered','Active','Confirmed']\n",
    "FEATURE = ['Obesity', 'Undernourished', 'Deaths','Recovered' ]\n",
    "\n",
    "ALL_OUTPUT = ['Alcoholic Beverages', 'Animal Products', 'Animal fats',\n",
    "       'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs',\n",
    "       'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat',\n",
    "       'Milk - Excluding Butter', 'Offals', 'Oilcrops', 'Pulses', 'Spices',\n",
    "       'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners',\n",
    "       'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables',\n",
    "       'Miscellaneous']\n",
    "GOOD_OUTPUT=['Animal Products', 'Animal fats','Vegetal Products','Vegetable Oils' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide trian and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(scaled_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold \n",
    "X = pd.DataFrame(scaled_df[FEATURE_CLS])\n",
    "y = pd.DataFrame(scaled_df[GOOD_OUTPUT])\n",
    "model = LinearRegression()\n",
    "scores = []\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "for i, (train, test) in enumerate(kfold.split(X, y)):\n",
    "    model.fit(X.iloc[train,:], y.iloc[train,:])\n",
    "    score = model.score(X.iloc[test,:], y.iloc[test,:])\n",
    "    scores.append(score)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def Regression(features, response, data, method = LinearRegression()):\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    return model.fit(X, Y)\n",
    "    \n",
    "    \n",
    "    \n",
    "def TestScore(features, response, data, model):\n",
    "    print('Output: ', response)\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    return model.score(X,Y)\n",
    "    \n",
    "def PlotRegression(features, response, data, model):\n",
    "    import matplotlib.pyplot as plt\n",
    "    X = data[features]\n",
    "    Y = data[response]\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(X, Y, s=10)\n",
    "    plt.plot(X, y_pred, color='r')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = Regression(FEATURE_CLS, GOOD_OUTPUT, train_set, method = linear_model.Lasso(alpha=0.1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestScore(FEATURE_CLS, GOOD_OUTPUT,test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PlotRegression(FEATURE_CLS, ALL_OUTPUT  ,tra in_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in ALL_OUTPUT:\n",
    "    model = Regression(FEATURE, cls, train_set, method = linear_model.Lasso(alpha=0.5) )\n",
    "    print('R^2 : ', TestScore(FEATURE, cls,test_set, model))\n",
    "    #PlotRegression(FEATURE, cls ,test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score of  Alcoholic Beverages  :  0.013679445596316286\n",
      "R^2 Score of  Animal Products  :  0.4071187818827652\n",
      "R^2 Score of  Animal fats  :  0.06527388789955368\n",
      "R^2 Score of  Aquatic Products, Other  :  -23.49228129638041\n",
      "R^2 Score of  Cereals - Excluding Beer  :  0.09168511175793215\n",
      "R^2 Score of  Eggs  :  0.3300471853373028\n",
      "R^2 Score of  Fish, Seafood  :  -0.3557799308508851\n",
      "R^2 Score of  Fruits - Excluding Wine  :  -0.003684530770110772\n",
      "R^2 Score of  Meat  :  0.2998893502210086\n",
      "R^2 Score of  Milk - Excluding Butter  :  0.2682181145804291\n",
      "R^2 Score of  Offals  :  -0.03980858625347028\n",
      "R^2 Score of  Oilcrops  :  0.19871315992927818\n",
      "R^2 Score of  Pulses  :  0.27010856336738553\n",
      "R^2 Score of  Spices  :  0.008008669410602853\n",
      "R^2 Score of  Starchy Roots  :  -0.1931332851319647\n",
      "R^2 Score of  Stimulants  :  0.024629228863092267\n",
      "R^2 Score of  Sugar Crops  :  -0.023077949450360125\n",
      "R^2 Score of  Sugar & Sweeteners  :  -0.3688133703764582\n",
      "R^2 Score of  Treenuts  :  0.1643990034616507\n",
      "R^2 Score of  Vegetal Products  :  0.40680966720667666\n",
      "R^2 Score of  Vegetable Oils  :  0.10250992841761075\n",
      "R^2 Score of  Vegetables  :  0.033058210624447915\n",
      "R^2 Score of  Miscellaneous  :  -0.10041597014979464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import linear_model\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE])\n",
    "    #print(X_train_transformed)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score of  Alcoholic Beverages  :  0.023695172725665348\n",
      "R^2 Score of  Animal Products  :  0.3510134168224909\n",
      "R^2 Score of  Animal fats  :  0.014688126292542014\n",
      "R^2 Score of  Aquatic Products, Other  :  -0.5231673484154225\n",
      "R^2 Score of  Cereals - Excluding Beer  :  0.1591925355379078\n",
      "R^2 Score of  Eggs  :  0.3194094649851641\n",
      "R^2 Score of  Fish, Seafood  :  -0.4564113754549344\n",
      "R^2 Score of  Fruits - Excluding Wine  :  -0.1684864119277405\n",
      "R^2 Score of  Meat  :  0.23361864335981253\n",
      "R^2 Score of  Milk - Excluding Butter  :  0.16942869817852813\n",
      "R^2 Score of  Offals  :  -0.20361247806190907\n",
      "R^2 Score of  Oilcrops  :  0.055371184191674305\n",
      "R^2 Score of  Pulses  :  0.29374664333806044\n",
      "R^2 Score of  Spices  :  -0.359425033689329\n",
      "R^2 Score of  Starchy Roots  :  -1.949817085268132\n",
      "R^2 Score of  Stimulants  :  -0.09935155371361581\n",
      "R^2 Score of  Sugar Crops  :  -0.5096826368553857\n",
      "R^2 Score of  Sugar & Sweeteners  :  -0.0017213940513807202\n",
      "R^2 Score of  Treenuts  :  0.1982350909084859\n",
      "R^2 Score of  Vegetal Products  :  0.3454610360083724\n",
      "R^2 Score of  Vegetable Oils  :  -0.010196459863296647\n",
      "R^2 Score of  Vegetables  :  0.0016893702113716103\n",
      "R^2 Score of  Miscellaneous  :  -2.5534442172842824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(max_depth=2)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE_CLS])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE_CLS])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score of  Alcoholic Beverages  :  0.017003167510382\n",
      "R^2 Score of  Animal Products  :  0.2649215841323306\n",
      "R^2 Score of  Animal fats  :  0.07871698084609091\n",
      "R^2 Score of  Aquatic Products, Other  :  -524.0858735810856\n",
      "R^2 Score of  Cereals - Excluding Beer  :  -0.1300902889672635\n",
      "R^2 Score of  Eggs  :  0.2681211835234144\n",
      "R^2 Score of  Fish, Seafood  :  -0.37681923906402237\n",
      "R^2 Score of  Fruits - Excluding Wine  :  -0.33862784599986884\n",
      "R^2 Score of  Meat  :  0.16291072808898444\n",
      "R^2 Score of  Milk - Excluding Butter  :  0.30773583521160086\n",
      "R^2 Score of  Offals  :  -0.15650866237992012\n",
      "R^2 Score of  Oilcrops  :  0.15149977754286414\n",
      "R^2 Score of  Pulses  :  0.14492755856996142\n",
      "R^2 Score of  Spices  :  0.06139779021112057\n",
      "R^2 Score of  Starchy Roots  :  -0.13462545662839465\n",
      "R^2 Score of  Stimulants  :  0.029246202709246716\n",
      "R^2 Score of  Sugar Crops  :  -0.44792750917774327\n",
      "R^2 Score of  Sugar & Sweeteners  :  -8.871950130470784\n",
      "R^2 Score of  Treenuts  :  0.14068593246847028\n",
      "R^2 Score of  Vegetal Products  :  0.2640253922682211\n",
      "R^2 Score of  Vegetable Oils  :  -0.19861939764009406\n",
      "R^2 Score of  Vegetables  :  -0.017801149181652764\n",
      "R^2 Score of  Miscellaneous  :  0.1461688103389478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model =  SVR(C=1.0, epsilon=0.1)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE_CLS])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE_CLS])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score of  Alcoholic Beverages  :  0.050689860976801615\n",
      "R^2 Score of  Animal Products  :  0.4370543195033666\n",
      "R^2 Score of  Animal fats  :  0.01076632750967288\n",
      "R^2 Score of  Aquatic Products, Other  :  -12.440796982616115\n",
      "R^2 Score of  Cereals - Excluding Beer  :  0.12368083443518374\n",
      "R^2 Score of  Eggs  :  0.3727350768573414\n",
      "R^2 Score of  Fish, Seafood  :  -0.30103730014823626\n",
      "R^2 Score of  Fruits - Excluding Wine  :  0.017507041362669673\n",
      "R^2 Score of  Meat  :  0.22075578333511248\n",
      "R^2 Score of  Milk - Excluding Butter  :  0.19010409141404372\n",
      "R^2 Score of  Offals  :  -0.029407867456864523\n",
      "R^2 Score of  Oilcrops  :  0.17636423230941312\n",
      "R^2 Score of  Pulses  :  0.3064948916226331\n",
      "R^2 Score of  Spices  :  -0.052245040693597256\n",
      "R^2 Score of  Starchy Roots  :  -0.7950447710429336\n",
      "R^2 Score of  Stimulants  :  -0.013742656439784007\n",
      "R^2 Score of  Sugar Crops  :  -0.24622207317746025\n",
      "R^2 Score of  Sugar & Sweeteners  :  -0.05367809944528612\n",
      "R^2 Score of  Treenuts  :  0.18165983825311438\n",
      "R^2 Score of  Vegetal Products  :  0.4367465678295841\n",
      "R^2 Score of  Vegetable Oils  :  0.0260525685259001\n",
      "R^2 Score of  Vegetables  :  0.075094336735675\n",
      "R^2 Score of  Miscellaneous  :  -0.7485410630775329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-9a2814d5bf12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_test_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATURE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(X_train_transformed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R^2 Score of '\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m' : '\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-venv/ds/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_no_change\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-venv/ds/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_validate_y\u001b[0;34m(self, y, sample_weight)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mn_trim_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-venv/ds/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "for cls in ALL_OUTPUT: \n",
    "    poly_transformer = PolynomialFeatures(1) \n",
    "    X_train_transformed = poly_transformer.fit_transform(train_set[FEATURE])\n",
    "    X_test_transformed = poly_transformer.fit_transform(test_set[FEATURE])\n",
    "    #print(X_train_transformed)\n",
    "    model.fit(X_train_transformed, train_set[cls])\n",
    "    score = model.score(X_test_transformed, test_set[cls])\n",
    "    print('R^2 Score of ' , cls ,' : ' , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
